{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Problems\n",
    "\n",
    "The hardest part of solving an optimization problem is often formulating the problem itself.  Optimization problems generally take the form\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{minimize}_x \\qquad &f(x)\\\\\n",
    "\\text{subject to} \\qquad &c_e(x) = 0 \\\\\n",
    "&c_i(x) \\le 0 \\\\\n",
    "& l \\le x \\le u\n",
    "\\end{align*}\n",
    "\n",
    "where $f(x)$ is some scalar function, $c_e(x)$ is a vector encoding equality constraints, and $c_i(x)$ is a vector encoding inequality constraints.\n",
    "\n",
    "**Equivalent formulations**\n",
    "Optimization problems can be represented in many equivalent ways. Typically specific solvers expect a certain form for the optimization problem, so if you're using a solver directly, you may need to transform your problem slightly. Modelling languages like JuMP avoid this by letting you formulate the problem however you want, and then they will transform your formulation into a standard form before passing it into a solver.\n",
    "\n",
    "For example, if a solver expects problems of the form\n",
    "\\begin{align*}\n",
    "\\text{minimize}_x \\qquad &f(x)\\\\\n",
    "\\text{subject to} \\qquad &c_e(x) = 0 \\\\\n",
    "& l \\le x \\le u\n",
    "\\end{align*}\n",
    "but we have a problem in the form \n",
    "\\begin{align*}\n",
    "\\text{minimize}_x \\qquad &f(x)\\\\\n",
    "\\text{subject to} \\qquad &c_i(x) \\leq 0 \\\\\n",
    "& l \\le x \\le u\n",
    "\\end{align*}\n",
    "we can add additional ``slack'' variables, so that $c_i(x) + s = 0$, and $s \\geq 0$, so that the same problem can be written as\n",
    "\\begin{align*}\n",
    "\\text{minimize}_{x,s} \\qquad &f(x)\\\\\n",
    "\\text{subject to} \\qquad &c_i(x) + s = 0 \\\\\n",
    "& l \\le x \\le u \\\\\n",
    "& 0 \\le s\n",
    "\\end{align*}\n",
    "\n",
    "## Exercise\n",
    "1. If the solver required that you optimize over $x \\geq 0$ only, how would you represent $x \\in \\mathbb{R}$?\n",
    "2. If the solver required that you only use equality constraints (so $c(x) = 0$ only) and bound constraints ($l \\le x \\le u$), how would you represent $l \\le c(x) \\le u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEOS\n",
    "NEOS is a free service originally developed at Argonne National Lab, and now hosted by the University of Wisconsin - Madison. You can submit optimization problems in various standard formats/modelling languages (AMPL, GAMS, CPLEX, MPS, C, Fortran, ...), and choose one of the available solvers (there are tons, including commercial ones!), and they will be solved on their servers (assuming you're allocated enough compute time).\n",
    "\n",
    "We won't have time to go over many of the modelling languages, but if you are given a problem to solve in one of these formats and you don't have the solvers installed on your machine, you can just submit a job to NEOS.\n",
    "\n",
    "# Exercise\n",
    "1. Download pilot4.zip from  http://stanford.edu/group/SOL/multiscale/models/quadLP/MPS/.\n",
    "2. Go to https://neos-server.org/neos/solvers/index.html and submit the job to any solver which takes MPS input for linear programs.\n",
    "3. What objective value do you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Optimization using JuMP\n",
    "\n",
    "\n",
    "# JuMP\n",
    "\n",
    "[JuMP](https://github.com/JuliaOpt/JuMP.jl) is a Julia package that provides a modeling language for general optimization problems.\n",
    "\n",
    "## Optimization in Julia\n",
    "\n",
    "Julia's optimization packages have become popular due to their ease of use, and variety of interfaces to mature solvers.  The main optimization functionality in Julia is provided by [JuliaOpt](http://www.juliaopt.org/).\n",
    "\n",
    "The two high-level interfaces that you are most likely to use are\n",
    "* [JuMP](https://github.com/JuliaOpt/JuMP.jl) - a modeling language for all sorts of optimization problems\n",
    "* [Convex.jl](https://github.com/JuliaOpt/Convex.jl) - a package for disciplined convex programming (like [CVX](http://cvxr.com/cvx/))\n",
    "\n",
    "There is a mid-level interface as well, [MathProgBase.jl](https://github.com/JuliaOpt/MathProgBase.jl).\n",
    "\n",
    "The powerful thing about all of the above is that it is largely **solver independent**. This means you can formulate the optimization problem with these packages, and then choose from a variety of solvers to use under the hood.  This is just like other modeling languages like AMPL - the reason why Julia's optimization packages have become popular is that they are generally easier to use than older modeling languages.\n",
    "\n",
    "## Solvers\n",
    "\n",
    "Today is more about turning your optimization models into something that can run on a computer via JuMP, but you still need a solver to actually solve the problem for you under the hood.  [JuliaOpt](http://www.juliaopt.org/) has a list of solvers that can be called from the high level interfaces (there are currently 20).  There are many open-source options available, but there are also interfaces to some of the big commercial solvers such as [Gurobi](http://www.gurobi.com/), [Mosek](https://www.mosek.com/), [Knitro](https://www.artelys.com/en/optimization-tools/knitro), etc. Many of these commercial solvers offer free academic/student licences, and if you are trying to solve large optimization problems they may be worth looking at. Note that these Julia are still being developed, and many solver interfaces may not yet offer the full capabilities of the underlying solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using Clp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Programming\n",
    "\n",
    "[Linear Programs (LPs)](https://en.wikipedia.org/wiki/Linear_programming) are optimization problems for which both the objective and constraint functions are linear.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{min or max}_{x\\in \\mathbb{R}^n} \\qquad &c^T x\\\\\n",
    "\\text{subject to }\\qquad &Ax = b \\\\\n",
    "&l \\le x \\le u\n",
    "\\end{align*}\n",
    "\n",
    "We'll start talking about how to construct models by using LPs as an example.\n",
    "\n",
    "LPs arise all over the place: maximizing profit, resource allocation, scheduling, max-flow...\n",
    "\n",
    "We'll explore how to build a model in JuMP by solving a max-flow problem by formulating it as an LP.\n",
    "\n",
    "**Max Flow Problems**\n",
    "We have a graph like the one below, and we can think of each edge, $e_i$, as a pipe which has some capacity for carrying water. Our goal is to route as much water as possible from node $s$ to node $t$.\n",
    "\n",
    "The constraints are the following:\n",
    "- a pipe carries a non-negative amount of water\n",
    "- an edge cannot carry more water than its capacity\n",
    "- the amount of water going into a node is equal to the amount of water exiting the node, except for $s$ and $t$\n",
    "\n",
    "![alt-text](max_flow_graph.png)\n",
    "\n",
    "Below, we'll encode this problem into a JuMP model, and then solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Define problem data for max-flow problem\n",
    "\n",
    "# Number of nodes and edges\n",
    "n = 6\n",
    "m = 8\n",
    "\n",
    "# Incidence matrix for graph\n",
    "# B(v,e) = -1 if edge e is exiting from node v\n",
    "#          +1 if edge e is entering node v\n",
    "\n",
    "# Thus flow constraint is that sum_{i=1}^m B(i,v) = 0 for all v != s,t\n",
    "# i.e. sum of across row of B is zero\n",
    "\n",
    "#        e1 e2 e3 e4 e5 e6 e7 e8\n",
    "B =     [-1 -1  0  0  0  0  0  0;  #v1\n",
    "          1  0 -1  0  0  1  0  0;  #v2\n",
    "          0  1  0 -1 -1  0  0  0;  #v3\n",
    "          0  0  1  0  1  0 -1  0;  #v4\n",
    "          0  0  0  1  0 -1  0 -1;  #v5\n",
    "          0  0  0  0  0  0  1  1]; #v6\n",
    "\n",
    "# Edge capacities\n",
    "c = [4 4 5 3 1 2 5 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{alignat*}{1}\\max\\quad & e_{1} + e_{2}\\\\\n",
       "\\text{Subject to} \\quad & e_{1} - e_{3} + e_{6} = 0\\\\\n",
       " & e_{2} - e_{4} - e_{5} = 0\\\\\n",
       " & e_{3} + e_{5} - e_{7} = 0\\\\\n",
       " & e_{4} - e_{6} - e_{8} = 0\\\\\n",
       " & 0 \\leq e_{1} \\leq 4\\\\\n",
       " & 0 \\leq e_{2} \\leq 4\\\\\n",
       " & 0 \\leq e_{3} \\leq 5\\\\\n",
       " & 0 \\leq e_{4} \\leq 3\\\\\n",
       " & 0 \\leq e_{5} \\leq 1\\\\\n",
       " & 0 \\leq e_{6} \\leq 2\\\\\n",
       " & 0 \\leq e_{7} \\leq 5\\\\\n",
       " & 0 \\leq e_{8} \\leq 2\\\\\n",
       "\\end{alignat*}\n",
       " $$"
      ],
      "text/plain": [
       "Maximization problem with:\n",
       " * 4 linear constraints\n",
       " * 8 variables\n",
       "Solver is ClpMathProg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a model\n",
    "mod = Model(solver=ClpSolver())\n",
    "\n",
    "# add variables (one for each edge)\n",
    "@variable(mod, 0 <= e[i=1:m] <= c[i])\n",
    "\n",
    "# Add flow conservation constraint\n",
    "# Note that we ignore s,t\n",
    "@constraint(mod, B[2:n-1,:]*e .== 0)\n",
    "\n",
    "# define objective\n",
    "@objective(mod, Max, e[1] + e[2])\n",
    "# prints problem we've defined\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal objective: 7.0.\n",
      "e = [4.0, 3.0, 4.0, 2.0, 1.0, 0.0, 5.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# solve the problem\n",
    "status = solve(mod)\n",
    "\n",
    "# print objective value, and the values of x,y\n",
    "println(\"Optimal objective: \",getobjectivevalue(mod), \n",
    "\".\\ne = \", getvalue(e))\n",
    "\n",
    "# status can be one of:\n",
    "# - :Optimal\n",
    "# - :Unbounded\n",
    "# - :Infeasible\n",
    "# - :UserLimit\n",
    "# - :Error\n",
    "# - :NotSolved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "1. Install another solver that will solve a Linear Program (see [JuliaOpt](http://www.juliaopt.org/) for options - look at the first column), and solve the above example using the new solver.\n",
    "2. Increase the capacity of edge 7 to be 4. What happens to the optimal flow?\n",
    "3. Add a constraint so that edge 7 and edge 8 have to have equal flow. What happens now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Programming\n",
    "\n",
    "[Quadratic Programs (QPs)](https://en.wikipedia.org/wiki/Quadratic_programming) allow the objective function $f(x)$ to be quadratic.  The optimization problems have the form\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{minimize}_{x\\in \\mathbb{R}^n} \\qquad &\\tfrac{1}{2}x^T Q x+c^T x\\\\\n",
    "\\text{subject to}\\qquad &Ax \\le b : y \\\\\n",
    "& l \\le x \\le u : z\n",
    "\\end{align*}\n",
    "\n",
    "Note that in the case that $Q$ is SPD, that the problem is convex, but this is generally not the case. Some solvers (particularly convex ones) will only accept SPD $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Ipopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "m = 3\n",
    "\n",
    "Q = rand(n,n)\n",
    "c = 2*rand(n,1)-1\n",
    "\n",
    "A = 2*rand(m,n)-1\n",
    "b = 2*rand(m,1)-1\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "# Parameters for the solver can be passed when constructing the solver\n",
    "# Available parameters depend on the solver\n",
    "mod2 = Model(solver=IpoptSolver(tol=1e-8))\n",
    "\n",
    "# add variables\n",
    "bnds = @variable(mod2, 0 <= x[1:n] <= 1)\n",
    "# add additional constraint\n",
    "@constraint(mod2, constr, A*x .<= b)\n",
    "# define objective\n",
    "obj = x'*Q*x + c'*x\n",
    "@objective(mod2, Min, obj[1])\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.6, running with linear solver ma27.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:       30\n",
      "Number of nonzeros in Lagrangian Hessian.............:      100\n",
      "\n",
      "Total number of variables............................:       10\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:       10\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        3\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        3\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  4.0980056e-03 2.12e-01 8.65e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  8.7108278e-03 1.93e-01 7.69e-01  -1.7 8.64e-02    -  1.30e-01 1.32e-01h  1\n",
      "   2  3.0135333e-01 0.00e+00 4.93e-01  -1.7 2.86e-01    -  6.47e-01 1.00e+00f  1\n",
      "   3  2.9133240e-01 0.00e+00 7.41e-01  -1.7 1.42e-01    -  9.93e-01 3.44e-01f  2\n",
      "   4  3.3668720e-01 0.00e+00 2.00e-07  -1.7 5.09e-02    -  1.00e+00 1.00e+00f  1\n",
      "   5  2.2212384e-01 0.00e+00 3.56e-02  -2.5 3.45e-02    -  8.86e-01 1.00e+00f  1\n",
      "   6  2.0146718e-01 0.00e+00 3.84e-02  -2.5 3.84e-02   0.0 1.00e+00 1.00e+00f  1\n",
      "   7  1.9534103e-01 0.00e+00 1.68e-01  -2.5 8.26e-01    -  1.98e-01 5.69e-02f  2\n",
      "   8  1.8903332e-01 0.00e+00 2.83e-08  -2.5 6.89e-02    -  1.00e+00 1.00e+00f  1\n",
      "   9  1.6993807e-01 0.00e+00 1.50e-09  -3.8 6.66e-03    -  1.00e+00 1.00e+00f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10  1.6833970e-01 0.00e+00 2.63e-03  -5.7 3.77e-03    -  9.09e-01 9.98e-01f  1\n",
      "  11  1.6816074e-01 0.00e+00 4.01e-02  -5.7 7.62e-02    -  9.29e-01 5.06e-01f  1\n",
      "  12  1.6815032e-01 0.00e+00 1.84e-11  -5.7 4.87e-04    -  1.00e+00 1.00e+00f  1\n",
      "  13  1.6813374e-01 0.00e+00 6.93e-07  -8.6 2.91e-04    -  9.98e-01 1.00e+00f  1\n",
      "  14  1.6813374e-01 0.00e+00 2.51e-14  -8.6 2.53e-07    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 14\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   1.6813374395026040e-01    1.6813374395026040e-01\n",
      "Dual infeasibility......:   2.5059035600428338e-14    2.5059035600428338e-14\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   2.5059104968608267e-09    2.5059104968608267e-09\n",
      "Overall NLP error.......:   2.5059104968608267e-09    2.5059104968608267e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 17\n",
      "Number of objective gradient evaluations             = 15\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 17\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 15\n",
      "Number of Lagrangian Hessian evaluations             = 14\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.009\n",
      "Total CPU secs in NLP function evaluations           =      0.001\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "Optimal objective: 0.1681337439502604.\n",
      "x = [0.0, 0.0, 0.0, 0.332397, 0.0, 0.0, 0.0, 0.30378, 1.73149e-7, 0.0]\n",
      "dual vars on bounds = [1.81348, 0.325111, 1.0302, 3.7853e-9, 0.603685, 0.611335, 0.931634, 4.64977e-9, 0.0136822, 1.75007]\n",
      "dual vars on constr = [-1.8347e-9; -1.37805; -6.54413e-8]\n"
     ]
    }
   ],
   "source": [
    "solve(mod2)\n",
    "println(\"Optimal objective: \",getobjectivevalue(mod2), \n",
    "\t\".\\nx = \", getvalue(x))\n",
    "\n",
    "println(\"dual vars on bounds = \", getdual(bnds)) # Dual variables z\n",
    "println(\"dual vars on constr = \", getdual(constr)) # Dual variables y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering primal and dual solutions\n",
    "\n",
    "JuMP (via MathProgBase) also computes the dual variables to constraints (for example, $y$ and $z$ in the above QP). These can be accessed via ``getdual(c)`` where ``c`` is a reference to the constraint.\n",
    "\n",
    "Dual variables give information on the sensitivity of the problem to the constraints. You can almost think of it as the derivative of the objective with respect to perturbing the constraints.\n",
    "\n",
    "For example, if the dual variable to a constraint is 0, then that means that if we perturb the constraint, then the objective value won't change (up to first order).\n",
    "\n",
    "If the dual variable is large, then changing to constraint a little will change the objective value a lot. For example, it's possible that loosening a constraint with a large dual multiplier a little bit can reduce the objective value substantially.\n",
    "\n",
    "**Fixed Variables**\n",
    "\n",
    "Fixed variables are those of the form\n",
    "\n",
    "``@variable(mod, x==5)``\n",
    "\n",
    "A couple things to be aware of:\n",
    "- JuMP still treats these as optimization variables like any others. It will **not** substitute the value.\n",
    "- This means that the problem class (linear, quadratic, conic, nonlinear...) is determined as if ``x`` is any other variable. So\n",
    "\n",
    "    ``@constraint(mod, xy = 1)``\n",
    "\n",
    "    is still a **not** a linear constraint.\n",
    "- Calling ``setvalue(x, v)`` will cause an error if ``v != 5``. Instead, use ``JuMP.fix(x,v)`` to change the fixed value.\n",
    "- Treating the fixed variables as regular variables can be useful to learn sensitivity information fromt the dual variable to that constraint. That is, we can learn how the problem depends on that variable's value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Problems\n",
    "\n",
    "- Swapping solvers: ``setsolver(mod, solverName)``\n",
    "- changing objective: just call ``@objective`` again\n",
    "- changing **scalar** variable bounds: ``setlowerbound(x, l)`` and ``setupperbound(x, u)``\n",
    "- changing **vector** variable bounds: ``setlowerbound.(x, l)`` and ``setupperbound.(x, u)`` (notice the dot)\n",
    "- adding constraints: just call ``@constraint()`` again\n",
    "- removing constraints: does not seem currently possible (so build a new model)\n",
    "- modify constraint right-hand side: ``JuMP.setRHS(constr, v)``\n",
    "\n",
    "It is possible to add new variables to existing constraints, as long as they appear as linear terms (so of the form ``+a*z`` for some scalar ``a`` and scalar variable ``z``). Otherwise, you would need to rebuild the model.\n",
    "\n",
    "Once you modify the problem, you'll need to call ``solve()`` again to see the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-order Cone Constraints\n",
    "\n",
    "http://www.juliaopt.org/JuMP.jl/0.18/refmodel.html#second-order-cone-constraints\n",
    "\n",
    "These are constraints of the form:\n",
    "\\begin{align*}\n",
    "\\|x_{1:n-1}\\| \\le x_n,\n",
    "\\end{align*}\n",
    "or more generally\n",
    "\\begin{align*}\n",
    "\\|Ax-b\\|_2 + a^T x + c \\le 0.\n",
    "\\end{align*}\n",
    "\n",
    "JuMP currently only supports conic programs with **linear** objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ECOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take QP from before and add second order cone constraint\n",
    "setsolver(mod2, ECOSSolver())\n",
    "\n",
    "k = 4;\n",
    "B = 2*rand(k,n)-1\n",
    "d = rand(k)\n",
    "a = rand(n)\n",
    "\n",
    "obj = c'*x\n",
    "setlowerbound.(x[1:n], -1)\n",
    "@objective(mod2, Min, obj[1])\n",
    "@constraint(mod2, norm(B*x - d) + a'*x <= 10)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal objective: -3.0819559277404283.\n",
      "x = [-1.0, 1.0, -1.0, -1.0, 1.0, 0.899435, -1.0, 1.0, -0.0487109, -1.0]\n",
      "\n",
      "ECOS 2.0.5 - (C) embotech GmbH, Zurich Switzerland, 2012-15. Web: www.embotech.com/ECOS\n",
      "\n",
      "It     pcost       dcost      gap   pres   dres    k/t    mu     step   sigma     IR    |   BT\n",
      " 0  +1.729e-01  -2.929e+01  +6e+01  3e-01  6e-01  1e+00  3e+00    ---    ---    1  1  - |  -  - \n",
      " 1  -1.402e+00  -5.745e+00  +2e+01  5e-02  2e-01  6e-01  7e-01  0.8109  1e-01   1  1  1 |  0  0\n",
      " 2  -2.829e+00  -3.433e+00  +2e+00  6e-03  3e-02  9e-02  1e-01  0.8678  2e-02   1  1  1 |  0  0\n",
      " 3  -2.981e+00  -3.177e+00  +7e-01  2e-03  9e-03  3e-02  3e-02  0.6947  2e-02   1  1  1 |  0  0\n",
      " 4  -3.075e+00  -3.099e+00  +9e-02  2e-04  1e-03  3e-03  4e-03  0.9040  3e-02   1  1  1 |  0  0\n",
      " 5  -3.081e+00  -3.083e+00  +8e-03  2e-05  1e-04  3e-04  4e-04  0.9236  2e-02   1  1  1 |  0  0\n",
      " 6  -3.082e+00  -3.082e+00  +9e-05  2e-07  1e-06  3e-06  4e-06  0.9890  1e-04   1  1  1 |  0  0\n",
      " 7  -3.082e+00  -3.082e+00  +1e-06  2e-09  1e-08  3e-08  4e-08  0.9890  1e-04   1  1  1 |  0  0\n",
      " 8  -3.082e+00  -3.082e+00  +1e-08  3e-11  1e-10  4e-10  5e-10  0.9890  1e-04   1  0  0 |  0  0\n",
      "\n",
      "OPTIMAL (within feastol=1.4e-10, reltol=3.7e-09, abstol=1.1e-08).\n",
      "Runtime: 0.000613 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solve(mod2)\n",
    "println(\"Optimal objective: \",getobjectivevalue(mod2), \n",
    "\t\".\\nx = \", getvalue(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semidefinite programming\n",
    "\n",
    "JuMP supports semidefinite programming as part of its conic programming capabilities. Thus it supports matrices as variables which are either symmetric $X = X^T$ or semidefinite $X \\succeq 0$, as well as semidefinite constraints.\n",
    "\n",
    "Thus we can solve semidefinite programs of the form\n",
    "\\begin{align*}\n",
    "\\min_{X} \\qquad & tr(C^T X) \\\\\n",
    "\\mbox{s.t. } \\qquad & tr(A_i^T X) = b_i, \\, i=1,\\dots, m \\\\\n",
    "& X \\succeq 0\n",
    "\\end{align*}\n",
    "\n",
    "To declare semidefinite/symmetric variables, use:\n",
    "\n",
    "``@variable(mod, X[1:n,1:n], SDP)``\n",
    "``@variable(mod, X[1:n,1:n], Symmetric)``\n",
    "\n",
    "and for semidefinite constraints, you use ``@SDconstraint``. For example:\n",
    "``@SDconstraint(mod, X >= A)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPrecompiling module SCS.\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "using SCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal objective: 108.96314739331747\n",
      "----------------------------------------------------------------------------\n",
      "\tSCS v1.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2016\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-direct, nnz in A = 2550\n",
      "eps = 1.00e-04, alpha = 1.80, max_iters = 20000, normalize = 1, scale = 5.00\n",
      "Variables n = 1275, constraints m = 2550\n",
      "Cones:\tsd vars: 2550, sd blks: 2\n",
      "Setup time: 5.69e-04s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0|      inf       inf      -nan      -inf       inf       inf  1.79e-03 \n",
      "    80| 1.06e-05  4.29e-05  1.13e-05  1.09e+02  1.09e+02  0.00e+00  9.91e-02 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Solved\n",
      "Timing: Solve time: 9.91e-02s\n",
      "\tLin-sys: nnz in L factor: 6375, avg solve time: 2.58e-05s\n",
      "\tCones: avg projection time: 1.17e-03s\n",
      "----------------------------------------------------------------------------\n",
      "Error metrics:\n",
      "dist(s, K) = 1.8486e-09, dist(y, K*) = 1.2502e-09, s'y/|s||y| = 1.5971e-12\n",
      "|Ax + s - b|_2 / (1 + |b|_2) = 1.0572e-05\n",
      "|A'y + c|_2 / (1 + |c|_2) = 4.2890e-05\n",
      "|c'x + b'y| / (1 + |c'x| + |b'y|) = 1.1290e-05\n",
      "----------------------------------------------------------------------------\n",
      "c'x = 108.9631, -b'y = 108.9656\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "mod4 = Model(solver=SCSSolver())\n",
    "\n",
    "n = 50\n",
    "A = rand(n,n)\n",
    "A = A+A';\n",
    "@variable(mod4, x>=0)\n",
    "@objective(mod4, Min, x)\n",
    "@SDconstraint(mod4, x*eye(n) >= A)\n",
    "\n",
    "solve(mod4)\n",
    "\n",
    "println(\"Optimal objective: \",getobjectivevalue(mod4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "We'll build a model for doing robust optimization using what we've covered so far.\n",
    "\n",
    "Suppose there are $n$ stocks, and suppose that the return of the stocks is a Gaussian random vector with mean $\\bar{p}$ and covariance $\\Sigma$. One simple model for determining what the optimal portfolio is (without short positions) while taking risk into account is the Markowitz model:\n",
    "\\begin{align*}\n",
    "\\max_{x \\in \\mathbb{R}^n} \\qquad & \\bar{p}^T x + \\frac{\\mu}{2} x^T \\Sigma x \\\\\n",
    "\\mbox{subject to} \\qquad & \\sum_{k=1}^n x_k = 1 \\\\\n",
    "& x \\geq 0\n",
    "\\end{align*}\n",
    "\n",
    "Try implementing this model with the given data below. What happens if you try different $\\mu$?\n",
    "\n",
    "Another approach maximizes the expected return while also bounding the probability that the return is less than a certain value. That is, given some $\\alpha$ and $\\beta < \\frac{1}{2}$ it will ensure that $P(\\bar{p}^T x \\le \\alpha) \\leq \\beta$.\n",
    "\n",
    "This can be modeled as the problem\n",
    "\\begin{align*}\n",
    "\\max_{x \\in \\mathbb{R}^n} \\qquad & \\bar{p}^T \\\\\n",
    "\\mbox{subject to} \\qquad & \\bar{p}^T x + \\Phi^{-1}(\\beta) \\|\\Sigma^{\\frac{1}{2}} x \\|_2 \\ge \\alpha\\\\\n",
    "& \\sum_{k=1}^n x_k = 1 \\\\\n",
    "& x \\geq 0\n",
    "\\end{align*}\n",
    "where $\\Phi$ is the CDF of a 1D Gaussian.\n",
    "\n",
    "Implement the above model, and compare the objective values to the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPrecompiling module Distributions.\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "# Pkg.add(\"Distributions\") #if you don't already have it\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: imported binding for beta overwritten in module Main\n"
     ]
    }
   ],
   "source": [
    "# Required data\n",
    "n = 10\n",
    "\n",
    "pbar = 10*rand(n)\n",
    "Sigma = rand(n,n)\n",
    "Sigma = Sigma'*Sigma + eye(n)\n",
    "G = chol(Sigma)\n",
    "G = Array{Float64, 2}(G)\n",
    "\n",
    "mu = 0.5\n",
    "alpha = 4\n",
    "beta = 0.1\n",
    "\n",
    "PhiB = quantile.(Normal(), [0, beta])[2] #Φ^{-1}(β)\n",
    ";"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
